---
title: "glycodash"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{glycodash}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}

#library(glycodash)
devtools::load_all()

```

This vignette gives an overview of the steps that are performed within the Glycodash dashboard and the options available to users. For more detailed information check the function documentation and comments in the modules.

## 1. Data import tab

The data import step can be broken down into 5 smaller steps:

1.  Upload a LaCyTools summary file.

2.  Link sample ID's to your data.

3.  Determine the sample types (e.g. blanks, pools, patient samples)

4.  Divide the analytes into clusters.

5.  Link metadata (e.g. age and sex of patients) to your data.

### 1.1 Upload a LaCyTools summary file

```{r upload-your-data}

# path_to_file <- system.file("extdata",
#                             "LacyTools_summary_example.txt",
#                             package = "glycodash")



# "LacyTools_summary_example.txt" has only IgGI cluster.
# "LaCyTools_summary_examply_extra_clusters.txt" has extra clusters:
# IgGI, IgGII, IgGIII, IgGIV
# Use this file for testing the custom derived traits feature.

path_to_file <- system.file("extdata",
                            "LacyTools_summary_example.txt",
                            package = "glycodash")

raw_LacyTools_summary <- read_non_rectangular(path = path_to_file, 
                                          delim = "\t")

LacyTools_summary <- convert_lacytools_summary(data = raw_LacyTools_summary)

LacyTools_summary <- detect_group(data = LacyTools_summary,
                                  keyword_specific = "Spike",
                                  keyword_total = "Total")

```

### 1.2 Add sample ID's

There are two methods to add sample ID's to your data:

1.  Upload a plate design

2.  Upload a sample list

```{r add-sample-IDs-with-plate-design}

path_to_plate_design <- system.file("extdata",
                                    "Plate_design_example.xlsx",
                                    package = "glycodash")

plate_design <- read_and_process_plate_design(
  plate_design_file = path_to_plate_design
)

summary_with_plate_well <- detect_plate_and_well(data = LacyTools_summary)

with_sample_ids <- dplyr::left_join(summary_with_plate_well,
                                    plate_design)

```

```{r add-sample-IDs-with-sample-list}

path_to_sample_list <- system.file("extdata",
                                   "Sample_list_example.xlsx",
                                   package = "glycodash")

sample_list <- process_sample_list(sample_list_file = path_to_sample_list)

summary_with_plate_well <- detect_plate_and_well(data = LacyTools_summary)

with_sample_ids <- dplyr::left_join(summary_with_plate_well,
                                    sample_list)


```

Based on the sample ID's a column is added to the data which indicates whether a sample has been measured in replicates.

```{r determine-replicates}

replicates <- with_sample_ids %>% 
  dplyr::select(tidyselect::any_of(c("sample_name", "sample_id", "group"))) %>% 
  dplyr::distinct() %>% 
  dplyr::group_by(dplyr::across(tidyselect::any_of("group"))) %>% 
  dplyr::add_count(sample_id, name = "number_of_replicates") %>% 
  dplyr::mutate(number_of_replicates = ifelse(
    sample_id == "empty cell in plate design",
    1,
    number_of_replicates
  )) %>% 
  dplyr::mutate(replicates = ifelse(number_of_replicates > 1, 
                                    TRUE, 
                                    FALSE)) %>% 
  dplyr::ungroup(.)

with_sample_ids <- dplyr::full_join(replicates, 
                                    with_sample_ids,
                                    multiple = "all")

```

### 1.3 Determine sample types

There are 2 methods to determine the sample types:

1.  Automatically based on the sample ID's.

2.  By uploading a sample types list.

```{r automatically-determine-sample_types}

with_sample_types <- with_sample_ids %>% 
  tidyr::extract(col = sample_id,
                 into = c("sample_type"),
                 regex = "([[:alpha:]]+)",
                 remove = FALSE) %>% 
  dplyr::mutate(
    sample_type = ifelse(
      sample_id == "empty cell in plate design",
      "unknown",
      sample_type
    ),
    sample_type = ifelse(is.na(sample_type),
                         "undetermined",
                         sample_type),
    sample_type = as.factor(sample_type)
  )

```

```{r upload-a-sample-types-list}

path_to_sample_type_file <- system.file("extdata",
                                        "Sample_types_example.xlsx",
                                        package = "glycodash")

sample_types <- read_sample_type_file(filepath = path_to_sample_type_file,
                                      filename = "Sample_types_example.xlsx")

with_sample_types <- dplyr::left_join(with_sample_ids,
                                      dplyr::distinct(sample_types)) %>% 
  dplyr::mutate(sample_type = as.factor(sample_type))
```

### 1.4 Divide analytes into clusters

The user needs to indicate the number of clusters and give a keyword for each cluster.

```{r clusters}

with_clusters <- define_clusters(data = with_sample_types,
                                 cluster_keywords = c("IgGI"))

# For example data with four clusters:
# cluster_keywords = c("IgGI", "IgGII", "IgGIII", "IgGIV")
```

### 1.5 Link metadata

This step is optional. Users can upload one or more metadata files (Excel or .rds).

```{r link-metadata}

# In this example only one metadata file is uploaded:
path_to_metadata <- system.file("extdata",
                                "Metadata_example.xlsx",
                                package = "glycodash")

metadata_list <- read_metadata(filepaths = list(path_to_metadata),
                               filenames = list("Metadata_example.xlsx"))

# For each metadata file, the user needs to select which column contains the sample ID's, in this case the "Sample ID" column:
sample_id_columns <- list("Sample ID")

# The sample ID column(s) selected by the user are then renamed to "sample_id" so the metadata can be merged (if there were multiple metadata files) and joined with the data:
prepped_metadata <- purrr::pmap(
  list(metadata_list,
       sample_id_columns),
  function(metadata, 
           sample_id_column) {
    renamed <- tryCatch(
      expr = {
        rename_sample_id_column(metadata = metadata,
                                sample_id_column = sample_id_column)
      },
      sample_id_conflict = function(c) {
        showNotification(c$message,
                         type = "warning",
                         duration = NULL)
        
        rename_sample_id_column(metadata = metadata,
                                sample_id_column = sample_id_column)
      })
    return(renamed)
  })

merged_metadata <- purrr::reduce(prepped_metadata,
                                 dplyr::full_join,
                                 by = "sample_id")

with_metadata <- dplyr::left_join(with_clusters,
                                  merged_metadata,
                                  by = "sample_id")

```

## 2. Spectra curation

There are 3 options for spectra curation:

1.  Curate spectra based on negative controls

2.  Curate spectra based on percentiles

3.  Skip spectra curation

For both option 1 and 2 analyte quality criteria are used to curate analytes within each spectrum. Then the sum intensity and percentage of passing analytes is calculated for each spectrum and shown in the spectra curation cut--off plot.

```{r sum-intenisty-and-percentage-of-passing-analytes}

# The user chooses the analyte quality criteria:
min_ppm_deviation <- -20
max_ppm_deviation <- 20
max_ipq <- 0.2
min_sn <- 9

# Hidden under 'Advanced settings'  the user can indicate which analyte quality criteria should be taken into account during spectra curation:
criteria_to_consider <- c("Mass accuracy",
                          "S/N",
                          "IPQ")

checked_data <- check_analyte_quality_criteria(
  my_data = with_metadata,
  min_ppm_deviation = min_ppm_deviation,
  max_ppm_deviation = max_ppm_deviation,
  max_ipq = max_ipq,
  min_sn = min_sn,
  criteria_to_consider = criteria_to_consider
)

summarized_checks <- summarize_spectra_checks(checked_data = checked_data)

# For each cluster in the data a tab is created on which a plot is shown. In this example there is only one cluster (IgGI):
cut_off_plot <- create_cut_off_plot(summarized_checks = summarized_checks)

plotly::ggplotly(cut_off_plot,
                 tooltip = "text")


```

### 2.1 Curate based on negative controls

The user chooses a group of samples of which the spectra should not pass curation (negative controls). The cut-off values for spectra curation will be set at a chosen percentile of the sum intensity and percentage of passing analytes in those negative control spectra.

```{r curate-spectra-based-on-negative-controls}

cut_offs_specific <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Spike",
  percentile = 97,
  use_mean_SD = FALSE,
  SD_factor = NULL,
  uncalibrated_as_NA = TRUE
)

cut_offs_total <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Total",
  percentile = 97,
  use_mean_SD = FALSE,
  SD_factor = NULL,
  uncalibrated_as_NA = TRUE
)

cut_offs <- dplyr::full_join(cut_offs_specific,
                             cut_offs_total)


```

When 'Show advanced settings' is checked by the user, the user can choose to use the mean and standard deviation (SD) instead of percentiles to calculate the sum intensity cut-off. The cut-off for the percentage of passing analytes is still calculated using the chosen percentile, but the cut-off for the sum intensity is calculated using the following formula:

cut-off ~sum intensity~ = mean ~sum intensity in negative controls~ + factor \* SD ~sum intensity in negative controls~

The user has to choose the factor to multiply the SD with.

```{r curate-spectra-based-on-negative-controls-with-mean-SD}

cut_offs_specific <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Spike",
  percentile = 97,
  use_mean_SD = TRUE,
  SD_factor = 3,
  uncalibrated_as_NA = TRUE
)

cut_offs_total <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Total",
  percentile = 97,
  use_mean_SD = TRUE,
  SD_factor = 3,
  uncalibrated_as_NA = TRUE
)

cut_offs_mean_SD <- dplyr::full_join(cut_offs_specific,
                                     cut_offs_total)


```

A final option available is to treat uncalibrated spectra either as missing values (NA) or as 0's.

```{r curate-spectra-based-on-negative-controls-uncalibrated-as-zeroes}

cut_offs_specific <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Spike",
  percentile = 97,
  use_mean_SD = FALSE,
  SD_factor = NULL,
  uncalibrated_as_NA = FALSE # Treat uncalibrated spectra as zeroes
)

cut_offs_total <- calculate_cut_offs(
  summarized_checks,
  control_sample_types = "PBS",
  group_keyword = "Total",
  percentile = 97,
  use_mean_SD = FALSE,
  SD_factor = NULL,
  uncalibrated_as_NA = FALSE # Treat uncalibrated spectra as zeroes
)

cut_offs_uncalibrated_as_zeroes <- dplyr::full_join(cut_offs_specific,
                                                    cut_offs_total)


```

```{r comparing-cut-offs-with-different options}

waldo::compare(cut_offs,
              cut_offs_mean_SD)

```

In this example, the cut-offs for the sum intensity are higher when using the mean SD option .

```{r comparing-cut-offs-with-different options2}

waldo::compare(cut_offs,
               cut_offs_uncalibrated_as_zeroes)
```

The cut-offs for the Spike samples are lower when uncalibrated spectra are treated as zeroes instead of as missing values.

### 2.2 Curate based on percentiles

The user chooses a percentile and the spectra with a sum intensity or passing analyte percentage below that percentile will fail curation. For example, if the chosen percentile is 2, then the "worst" 2 percent of spectra will fail curation.

The user can choose which sample types should not be taken into account when calculating the cut-off values. This way, the cut-offs can be based on only real samples instead of on blanks and standards as well.

The option to treat uncalibrated spectra either as missing values (NA) or as 0's is also available.

```{r curate-spectra-based-on-percentiles}

cut_offs_percentiles <- calculate_cut_offs(
  summarized_checks = summarized_checks,
  percentile = 2,
  exclude_sample_types = c("PBS", "Visucon", "IVIGg"), # These sample types are not taken into consideration when calculating the cut-off values.
  uncalibrated_as_NA = TRUE
)

```

After the cut-offs have been calculated with one of the two methods, the cut-offs are shown in the plot from before:

```{r cut-off-plot}

summarized_checks_with_cut_offs <- dplyr::full_join(summarized_checks,
                                                    cut_offs)

cut_off_plot_with_cut_offs <- cut_off_plot +
  ggplot2::geom_vline(data = summarized_checks_with_cut_offs,
                      ggplot2::aes(
                        xintercept = cut_off_passing_analyte_percentage,
                        text = paste0("Passing analyte percentage cut-off: ",
                                      cut_off_passing_analyte_percentage)
                      ),
                      linetype = "dotted") +
  ggplot2::geom_hline(data = summarized_checks_with_cut_offs,
                      ggplot2::aes(
                        yintercept = cut_off_sum_intensity,
                        text = paste0("Sum intensity cut-off: ",
                                      cut_off_sum_intensity)
                      ),
                      linetype = "dotted")

plotly::ggplotly(cut_off_plot_with_cut_offs,
                 tooltip = "text")

```

The user has the option to change the cut-off values manually.

The cut-off values are shown in a table beneath the cut-off plot:

```{r cut-offs-table}

for_cut_off_table <- cut_offs %>% 
        dplyr::mutate(
          `Based on sample types` = purrr::map_chr(
            sample_type_list,
            ~ paste("Yes,",
                    comma_and(.x$sample_type))),
          curation_method = firstupper(
            stringr::str_replace_all(curation_method,
                                     pattern = "_",
                                     replacement = " "))) %>% 
        dplyr::ungroup() %>% 
        dplyr::select(-c(cluster,
                         sample_type_list)) %>% 
        dplyr::rename("Cut-off sum intensity" = cut_off_sum_intensity,
                      "Cut-off percentage of passing analytes" = cut_off_passing_analyte_percentage,
                      "Curation method" = curation_method) %>% 
        dplyr::rename_with(firstupper)

DT::datatable(for_cut_off_table,
              rownames = FALSE,
              width = "600px",
              options = list(searching = FALSE,
                             paging = FALSE,
                             info = FALSE))

```

In case the user has chosen cut-offs manually those are also shown in the cut-off table.

When the user clicks on the perform spectra curation button the cut-offs are used to curate the spectra.

```{r perform-spectra-curation}

curated_spectra <- curate_spectra(checked_data = checked_data,
                                  summarized_checks = summarized_checks,
                                  cut_offs = cut_offs)

passing_spectra <- kick_out_spectra(curated_spectra = curated_spectra)

for_analyte_curation <- remove_unneeded_columns(passing_spectra = passing_spectra)

```

### 2.3 Spectra curation results

The results of the spectra curation are visualized in the "View spectra curation box" where a plot and two tables are shown.

```{r curated-spectra-plot}

curated_spectra_plot <- plot_spectra_curation_results(
  curated_data = curated_spectra, 
  total_and_specific = "Yes"
)

plotly::ggplotly(curated_spectra_plot,
                 tooltip = "text")

```

```{r overview-of-failed-spectra}

for_table <- curated_spectra %>% 
  dplyr::select(1:cut_off_passing_analyte_percentage) %>% 
  dplyr::distinct() %>% 
  dplyr::filter(!has_passed_spectra_curation)

DT::datatable(for_table,
              options = list(scrollX = TRUE,
                             filter = "top"))


```

```{r details-of-failed-spectra}

DT::datatable(curated_spectra %>% 
                dplyr::select(-(passing_analyte_percentage:replicates)) %>% 
                dplyr::distinct() %>% 
                dplyr::filter(has_passed_spectra_curation == FALSE),
              options = list(scrollX = TRUE,
                             searching = TRUE))

```

## 3. Analyte curation

### 3.1 Methods for analyte curation

There are two methods for analyte curation:

1.  Curate based on the data

2.  Upload an analyte list

#### 3.1.1 Curate analytes based on data

Analyte curation is based on the analyte quality criteria that the user has chosen on the 'Spectra curation' tab. In contrast to during spectra curation, all analyte quality criteria have to be taken into account now. Therefore the analyte quality criteria need to be checked again in case the user used the advanced setting criteria_to_consider during spectra curation.

The user can specify which sample types or groups (total or specific samples) should be ignored during analyte curation.

```{r checking-analyte-quality-criteria}

# In this example analyte curation is based only on the Spike pool samples:
without_samples_to_ignore <- throw_out_samples(
  passing_spectra = for_analyte_curation,
  # samples_to_ignore = c("PBS", "IVIGg", "Visucon", "Total")
  samples_to_ignore = c("PBS", "IVIGg", "Visucon") 
  # Removed Total for example of analyte curation per group
)

checked_analytes <- check_analyte_quality_criteria(
  my_data = without_samples_to_ignore,
  min_ppm_deviation = min_ppm_deviation,
  max_ppm_deviation = max_ppm_deviation,
  max_ipq = max_ipq,
  min_sn = min_sn,
  criteria_to_consider = c("Mass accuracy",
                           "IPQ",
                           "S/N")) # All criteria are taken into account during analyte curation, regardless of the advanced setting in the 'Spectra curation' tab.

```

In addition the user chooses a percentage of spectra (not including the sample types to ignore) in which an analyte needs to fulfill the analyte quality criteria in order to pass analyte curation.

It is also possible (not required) to perform the analyte curation per biological group.

```{r curate-analytes}

cut_off_percentage <- 25


# Curate analytes, but not per biological group.
curated_analytes <- curate_analytes(checked_analytes, cut_off_percentage)

# Curate analytes per biological group
# Note that the biological groups column can have any name.
curated_analytes_group <- curate_analytes(
  checked_analytes, cut_off_percentage, "group"
  ) 

# Create a consensus analyte list
consensus_list <- curated_analytes_group %>% 
  dplyr::select(cluster, charge, analyte, has_passed_analyte_curation) %>% 
  dplyr::group_by(cluster, charge, analyte) %>% 
  dplyr::mutate(pass_n = sum(has_passed_analyte_curation == TRUE)) %>% 
  dplyr::ungroup()
```

*In plotting curated_analytes_group: facet by group in addition to charge.*

*In the table: show all analytes and select which pass based on consensus list.*

#### 3.1.2 Upload an analyte list

The user can upload a list with analytes that should pass curation. All analytes not on this list will fail curation.

```{r curate-analytes-with-a-list}

path_to_analyte_list <- system.file("extdata",
                                    "Analyte_list.xlsx",
                                    package = "glycodash")

analyte_list <- readxl::read_excel(path_to_analyte_list)

curated_analytes_with_list <- curate_analytes_with_list(
  passing_spectra = for_analyte_curation,
  analyte_list = analyte_list
)

```

```{r}
analyte_curated_data <- dplyr::left_join(curated_analytes, 
                                         for_analyte_curation,
                                         multiple = "all")

for_normalization <- analyte_curated_data %>%
   dplyr::filter(has_passed_analyte_curation) %>%
   dplyr::select(-c(has_passed_analyte_curation, passing_percentage))

```

### 3.2 Analyte curation results

For each cluster a tab is created showing the results of the analyte curation. Each tab contains a plot and a table.

```{r plot-analyte-curation-results}

(
curated_analytes_plot <- plot_analyte_curation(
  curated_analytes = curated_analytes_group,
  cut_off_percentage = cut_off_percentage,
  selected_cluster = "IgGI",
  bio_groups_colname = "group"
)
)

plotly::ggplotly(p = curated_analytes_plot,
                 tooltip = "text")
```

In the dashboard the table has an additional column with check-boxes for each charge column. The analytes that are checked in that table are the ones that are included in the further steps. Here a simplified version of the table is shown, because the check-boxes are shiny inputs and I can't use them in this Rmarkdown file.

```{r curated-analytes-table}

table <- prepare_analyte_curation_table(
  analyte_curated_data = analyte_curated_data,
  selected_cluster = "IgGI", by_group = FALSE
)

DT::datatable(table)

```

## 4. Normalization

Total area normalization is performed per cluster.

```{r total-area-normalization}
# First, for each glycopeptide the total sum intensity of all charge states (divided by their fraction) together is calculated:
total_intensities <- calculate_total_intensity(for_normalization)

# And then the relative abundance of each glycopeptide is calculated per cluster:
normalized_data <- normalize_data(total_intensities)


# The normalized data is shown in a wide format (a column for each glycopeptide):
normalized_data_wide <- normalized_data %>% 
  # removing columns no longer needed with values that differ between clusters:
  dplyr::select(-tidyselect::any_of(c("passing_analyte_percentage", 
                                      "cut_off_passing_analyte_percentage", 
                                      "cut_off_sum_intensity"))) %>% 
  tidyr::pivot_wider(names_from = c(cluster, analyte),
                     names_sep = "_",
                     values_from = relative_abundance) %>% 
  
  # Add metadata again
  dplyr::left_join(., merged_metadata, by = "sample_id")

```

## 5. Derived traits

For automatically calculating default derived traits, the user can select which of the 4 derived traits should be calculated. The derived traits are calculated per cluster.

Currently, derived traits can only be calculated automatically for IgG.

```{r calculate-derived-traits}

traits_to_calculate <- c("Fucosylation", 
                         "Sialylation")

# First the derived traits are calculated
derived_traits <- calculate_derived_traits(
  data = normalized_data,
  selected_derived_traits = traits_to_calculate
)

# Then they are added to the normalized data in wide format:
data_with_derived_traits <- dplyr::full_join(normalized_data_wide,
                                             derived_traits) %>% 
  dplyr::select(-tidyselect::ends_with("formula")) %>% 
  tidyr::pivot_wider(names_from = cluster,
                     values_from = dplyr::any_of(traits_to_calculate),
                     names_glue = "{cluster}_{.value}")

```

The user can also calculate custom derived traits by uploading an Excel file.

```{r calculate-custom-traits}
# Load example file with custom derived traits
path_to_traits_formulas <- system.file("extdata",
                                       "Custom_traits_formulas_example.xlsx",
                                       package = "glycodash")

custom_traits_formulas <- readxl::read_excel(path_to_traits_formulas, 
                                             col_names = FALSE)



# Calculate custom derived traits
custom_traits <- calculate_custom_traits(normalized_data,
                                         custom_traits_formulas)



# Next: join custom traits data frame with normalized data in wide format,
# to get the a data frame similar to "data_with_derived_traits"

data_with_custom_traits <- dplyr::full_join(normalized_data_wide,
                                            custom_traits) %>%
  dplyr::select(-tidyselect::ends_with("formula"))
```

Combine the default derived traits with the custom derived traits.

```{r}
# Combine custom traits with default traits
data_with_all_traits <- dplyr::full_join(
  data_with_derived_traits, data_with_custom_traits
)
```

The formulas that have been used to calculate the derived traits are shown in a table.

```{r derived-traits-formulas}

formulas <- derived_traits %>% 
  dplyr::select(tidyselect::ends_with("formula"), cluster) %>% 
  dplyr::distinct() %>% 
  tidyr::pivot_longer(cols = -cluster,
                      names_to = "Derived trait",
                      values_to = "Formula") %>% 
  dplyr::rename_with(.fn = firstupper, 
                     .cols = cluster) %>% 
  dplyr::mutate(`Derived trait` = dplyr::recode(
    `Derived trait`,
    fuc_formula = "Fucosylation",
    gal_formula = "Galactosylation",
    sial_formula = "Sialylation",
    bis_formula = "Bisection"
  ))

DT::datatable(formulas,
              rownames = FALSE, 
              options = list(paging = FALSE,
                             ordering = FALSE,
                             searching = FALSE))

```

Show table with custom trait formulas.

```{r custom-traits-table}

# Just get these from the Excel file
custom_formulas <- custom_traits_formulas %>% 
  dplyr::rename(cluster = ...1) %>% 
  dplyr::rename(trait_formula = ...2) %>% 
  tidyr::separate(trait_formula, into = c("custom_trait", "formula"),
                  sep = "=", remove = TRUE)

DT::datatable(custom_formulas,
              colnames = c("Cluster", "Custom trait", "Formula"))
```

## 6. Repeatability

The user can select a sample ID of which replicates have been measured and are still in the data after the spectra curation step.

```{r find-replicates}

# The function below is used to identify all the replicates still in the data after spectra curation:
choices <- find_choices_for_repeatability_menu(
  normalized_data = normalized_data
) 

# These choices are shown to the user in a selectInput menu:
choices

```

The user can also indicate with the "Group by plate" switch if they want to assess the repeatability grouped by plate or with all plates together. Then when the "assess repeatability" button is clicked a plot is created.

### 6.1 Grouped by plate

If the user has chosen "Group by plate" then the mean relative abundances per plate and the relative standard deviations (RSDs) per plate are calculated for each analyte.

```{r mean-and-RSD-per-plate}

repeatability_stats <- calculate_repeatability_stats(
  data = normalized_data,
  standard_sample_id = "pool",
  standard_group = "Spike"
)

```

Then for each plate the intra-plate variation (the mean of the RSDs) is calculated. In addition the inter-plate variation (mean of the intra-plate variations) is calculated. These values are shown in a table.

```{r variation-table}

variations <- repeatability_stats %>% 
        dplyr::group_by(plate) %>% 
        dplyr::summarise(intra_plate_variation = signif(mean(RSD, na.rm = TRUE),
                                                        digits = 3))

sketch <- htmltools::withTags(table(
  DT::tableHeader(c("Plate", "Intra-plate variation (%)")),
  DT::tableFooter(c("Inter-plate variation (%)", 
                    signif(mean(variations$intra_plate_variation, 
                                na.rm = TRUE),
                           digits = 3)))
))

DT::datatable(data = variations,
              container = sketch,
              rownames = FALSE,
              filter = "none",
              options = list(searching = FALSE,
                             paging = FALSE))


```

The means and RSDs per plate are also shown in a bar plot. The bars represent the mean relative abundance and the points represent the RSD. This plot is faceted per cluster.

```{r repeatability-plot-by-plate}

repeatability_plot_by_plate <- visualize_repeatability(
  repeatability_stats,
  selected_group = "Spike",
  selected_sample_id = "pool"
)

# The "text" aestethic of the ggplot object can be used to show information on hover in the plotly (see function documentation for more info)
plotly::ggplotly(repeatability_plot_by_plate,
                 tooltip = "text")

```

### 6.2 All plates together

If the user chooses not to "Group by plate" then the mean relative abundance and RSD of each analyte is calculated for all samples together (regardless of the plate number). These values are then shown in a bar plot.

```{r repeatability-plot-not-by-plate}

repeatability_plot_not_by_plate <- visualize_repeatability_mean_bars(
  normalized_data,
  selected_sample_id = "pool",
  selected_group = "Spike"
)

plotly::ggplotly(repeatability_plot_not_by_plate,
                 tooltip = "text")

```

## 7. Data exploration

On the data exploration tab the user can create figures to explore the data. By clicking the "Add a tab +" button the user can create more figures. The types of plots available are:

1.  Box plot

2.  Scatter plot

3.  Histogram

The user can choose which sample types should not be shown in the plot, which variables should be on the x- and y-axes (exception: for histogram only the x-axis variable is chosen), what variable(s) should be used as facets and what variable should be represented with color. The facets and colors are optional.

```{r filtering-data}

filter <- c("PBS", "IVIGg")

filtered_data <- data_with_derived_traits %>% 
  dplyr::filter(!(sample_type %in% filter))
```

```{r boxplot}

xvar <- "sample_type"
yvar <- "IgGI_Fucosylation"
color <- "sample_type"
facets <- "group"

my_boxplot(filtered_data,
           xvar = xvar,
           yvar = yvar,
           color = color,
           facets = facets)

```

```{r scatter-plot}

xvar <- "IgGI_Sialylation"
yvar <- "IgGI_Fucosylation"
color <- NULL
facets <- c("group", "sample_type")

my_scatter_plot(filtered_data,
                xvar = xvar,
                yvar = yvar,
                color = color,
                facets = facets)


```

```{r histogram}

xvar <- "IgGI_Sialylation"
color <- "sample_type"
facets <- "group"

my_histogram(filtered_data,
             xvar = xvar,
             color = color,
             facets = facets)
```
